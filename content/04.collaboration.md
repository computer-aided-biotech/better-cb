## Level 2: Collaboration

Collaboration is a key aspect of scientific research, but it is especially relevant in computational biology, where interdisciplinary knowledge is often needed. Collaborators can take different forms: your boss or advisor, colleagues or lab mates, other laboratories, people from academia or industry, or your future self (as discussed in Level 1). Although collaborators can have a wide range of involvement with your project—from co-authors to commenters—they all share a direct relationship with you and your research, comprising a group of a dozen of people at most (contrary to a community, which is an open group of a large number of people, as we will discuss in Level 3). Each type of collaboration requires its own set of good practices, which we will cover in the next paragraphs.

### 2.1 Share code

Sharing code is one of the most common practices in software development, where large teams work together developing highly complex functions and scripts. Although computational biology projects are usually not as big, proper ways of sharing code are still essential, as it is not desired to have file conflicts as soon as two different researchers change the same piece of code. As mentioned in the previous section, hosting services such as GitHub [@https://github.com], GitLab [@https://gitlab.com] and Bitbucket [@https://bitbucket.org] (Table @tbl:collaboration-tools) allow for having a Git repository stored online, by creating a copy of the repository known as the "remote", which becomes the official version of the repository. The key advantage of using a remote is that there will be no direct interaction between different local copies of the repository, also known as a "clones", but instead each clone only will interact with the remote, and can only update the remote if there are no conflicts. This way, if a collaborator updated the repository with some changes, another collaborator will not be able to send their changes until they make sure to update their local copy with the changes already present online.

Tools for collaborative research. {#tbl:collaboration-tools}

| Goal | Tools |
| --- | ---------- |
| Share code | &bull; _Hosting services_: **GitHub** [@https://github.com], **GitLab** [@https://gitlab.com], **Bitbucket** [@https://bitbucket.org]. <br />&bull; _Git branching strategies:_ **Github flow** [@https://guides.github.com/introduction/flow/].<br />&bull; _Tests:_ correctness (e.g. **pytest** [@https://docs.pytest.org/en/stable/]), coverage (e.g. **codecov** [@https://about.codecov.io/]), automation (e.g. **tox** [@https://tox.readthedocs.io/en/latest/], **Travis CI** [@https://travis-ci.com/], **Github Actions** [@https://github.com/features/actions]).<br />&bull; _Code reviews_: **Github** [@https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/reviewing-changes-in-pull-requests], **Crucible** [@https://www.atlassian.com/software/crucible], **Upsource** [@https://www.jetbrains.com/upsource/]. |
| Share data | &bull; _Data version control_<br />&bull; _FAIR principles_<br />&bull; _Tidy data_ |
| Share data science notebooks | &bull; _Static:_ **GitHub**, **GitLab**, **NBviewer** [@https://nbviewer.jupyter.org/]. <br />&bull; _Interactive:_ **Binder** [@https://mybinder.org], **Google CoLab** [@https://colab.research.google.com/].<br />&bull; _Comparative:_ **ReviewNB** [@https://www.reviewnb.com/]. |
| Share workflows | • _General hosting services_: **GitHub**, **GitLab**, **Bitbucket**<br />• _Dedicated workflow repositories:_ **WorkflowHub** [@https://workflowhub.eu/] |
| Share manuscripts | &bull; _General-purpose word processors:_ **Google Docs** [@https://www.google.com/docs/about/], **Office 365** [@https://www.microsoft.com/en-us/microsoft-365].<br />&bull; _Scholarly word processors:_ **Authorea** [@https://www.authorea.com/].<br />&bull; _Online applications supporting Markup Languages:_ **Overleaf** (LaTeX) [@https://www.overleaf.com/], **Manubot** (Markdown + GitHub) [@https://manubot.org/]. |

In order to guarantee that different collaborators can work simultaneously in the same repository, a good idea is to implement some type of branching strategy in the repository (Table @tbl:collaboration-tools). In a small team of collaborators, the most common strategy is to have a single `master` branch and generate from it branches that each different developer can work on. Then, whenever the developer is ready, they can request to combine, or "merge", the changes from their branch into the master branch, in a process known as "pull request", or PR for short. Once a PR has been opened, collaborators can review it, and if it fulfills their criteria, approve it so that it can be merged into the master branch: any succeeding branches will now have those commits already included as part of their history. This branching strategy is sometimes referred to as Github flow [@https://guides.github.com/introduction/flow/] and will suffice for most projects. For more complex branching systems, see Section [3.3: Make your research sustainable](#make-your-research-sustainable).

Using Git hosting services for collaboration has many additional benefits. The commit history not only shows what was done at each point in time, but also which collaborator did it, so that if e.g. a bug was introduced, commands such as `git blame` will show which collaborator caused it. Collaborators can also create "forks", i.e. full copies of repositories under their own possession, for e.g. having different a version of the software that works for a different purpose. Git hosting services can be accessed interactively online, or from the terminal with tools such as GitHub CLI [@https://cli.github.com/]. Finally, Git hosting services also allow collaborators to open issues [@https://docs.github.com/en/github/managing-your-work-on-github/about-issues] for listing pending to-do's and/or asking questions, acting as an open forum for development discussions, which has the advantage of remaining accessible for the future, if new collaborators would join the research project later (as opposed to closed e-mail discussions). We will discuss additional advantages of using Git hosting services, in terms of interacting with a user base, in [Level 3: Community](#level-3-community).

Another important concept to internalize when developing code, especially together with other collaborators, is to develop unit tests (Table @tbl:collaboration-tools). Unit tests are scripts that will run to determine if specific modules/functions work as intended within the codebase, so that if later the function grows in scope, its proper basic functioning is ensured. For instance, if a function was defined for adding numbers, a simple test would be to asses if the function outputs 13 when the inputs 6 and 7 are provided. Tools such as `pytest` [@https://docs.pytest.org/en/stable/] for Python and `testthat` [@https://testthat.r-lib.org/] for R exist to then detect said scripts, and run all of them to display if any specific section is failing. It is a very good practice to develop tests at the same time you develop code (at the personal research level), as adding tests _a posteriori_ is significantly harder (but sometimes inevitable). Going beyond testing correctness, tools such as `flake8` [@https://flake8.pycqa.org/en/latest/] will test styling preferences (for complying with PEP8), `safety` [@https://pyup.io/safety/] will test for vulnerabilities among the software's dependencies, and Codecov [@https://about.codecov.io/] will test which percentage of the codebase is tested, given that as a rule of thumb, the more code lines tested, the more reliable a software is. All these different types of tests can be funneled into a single testing pipeline that can run automatically whenever desired. This process is known as Continuous Integration (CI), and can be tuned to run locally whenever commits are made, or online whenever a pull request is opened and/or merged. When running locally, an environment manager / command line tool such as `tox` [@https://tox.readthedocs.io/en/latest/] helps to ensure all tests are ran under e.g. different python versions. For setting up the CI cycle online, different dedicated CI tools such as Travis CI [@https://travis-ci.com/] or Circle CI [@https://circleci.com/] exist, and more recently GitHub actions [@https://github.com/features/actions] has been introduced for running the integration directly from Github.

Having tests is a great way of ensuring code fulfills a certain level of correctness and styling. However, it is no replacement for a human assessment to see if the code is correct, necessary and useful. Therefore, code reviewing is essential whenever developing code in collaboration (Table @tbl:collaboration-tools). Tools such as Crucible [@https://www.atlassian.com/software/crucible] and Upsource [@https://www.jetbrains.com/upsource/] exist for making in-line reviews of each file, but the most common approach, if the software is stored in a repository, is to directly review using the online review tools from the hosting service. In the case of Github [@https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/reviewing-changes-in-pull-requests], this not only allows the reviewer to open a comment in any line of the code (which creates a thread for the original author to reply in), but also to suggest changes, for the author to in turn approve/dismiss. When reviewing, there are a series of things to look for (from functionality to documentation), and good practices to keep in mind (such as phrasing the comments in a constructive way), which are outside of the scope of this review but presented in detail elsewhere [@https://google.github.io/eng-practices/review/reviewer/; @https://phauer.com/2018/code-review-guidelines/].

### 2.2 Share data

* Data:
  * FAIR principles
  * tidy data [@doi:10.18637/jss.v059.i10]
* Data version control:
  * Repositories: Zenodo, figshare
  * git LFS
  * dvc [@https://dvc.org/]

### 2.3 Share data science notebooks

As we previously discussed, Jupyter Notebook have become a fundamental tool of data analytics. Accordingly, you will likely need to share your notebook with collaborators at some point. To do this, there are static and interactive options. The former, as the name indicates, share computational notebooks as a rendered text, written internally in HTML. Static notebooks are a good option when you want to avoid any modifications and can work as an archive of past analyses, but interacting with its content is cumbersome—the file must be downloaded and run in a local Jupyter installation. Git-based code repositories, such as GitHub and GitLab, automatically render notebooks that can be later shared pointing collaborators to the GitHub repository. To ease this process, the Project Jupyter provides a web application called NBviewer, where you can paste a Jupyter Notebook's URL, publicly hosted in GitHub or elsewhere, and renders the file into a static HTML web page with a stable link. 

Interactive notebooks, in the other hand, not only render the file but also allow collaborators to fully interact with it, tinkering parameters or trying new input data—no installation required. The Binder Projects (which is also part of the Project Jupyter) offers the Binder service, where any publicly hosted Git-based repository can be open with a Jupyter Notebook interface. The user can fully interact with any notebook within the repository, although changes will not be saved to the original file. The platforms supports Python and R among other languages, and any additional packages required  to run the analysis need to be specified in a configuration file within the repository. Similarly, Jupyter Notebooks can be run interactively using Google CoLaboratory (CoLab), which is available to anyone with a Google account. Notebooks can be updated locally, from any public GitHub repository, or from Google Drive, where also imported files are also saved. In both cases, the machines provided by these services are comparable to a modern laptop. Thus, these tools are not suitable for some computing-intensive tasks common to computational biology problems.

Besides sharing notebooks, oftentimes computational biologists need to work and edit a notebook together. In those cases, notebooks need to be treated as any other piece of code: updates from different collaborators must be managed with version control in a platform such as GitHub. The problem, however, is that Git-based hosting services deal with notebooks as if they were HTML text, where changes between versions are hard to visualize. To better compare these changes, there is NBreview, which renders and display in parallel the old and new versions of a notebook for easy comparison. The tool can be easily installed using your GitHub account, and notebooks can be reviewed from their website.

### 2.4 Share computational workflows 

Computational biology projects often demands sharing multi-step analyses with dozens of third-party software and dependencies. Although these steps can be shared as documentation, complex workflows are better shared as stand-alone code that can be easily run with minimal file manipulation from collaborators. Doing so can safeguard the reproducibility and replicability of the analysis, leading to better science and less issues down the road. 

The simplest way to share a pipeline is to generate a Bash script that receives input files from the command line, thus, allowing to run it with different input data. However, Bash scripts offer little control over the overall workflow and cannot re-run specific parts of the pipeline. To address these issues, pipelines are better shared using a workflow automation system. Theoretically, all the instructions regarding the workflow could be written in the main pipeline file—in Snakemake, the `.smk` file (or Snakefile); in Nextflow, te `.nf` file; and in CWL, `.cwl` file. However, to ensure reproducibility, it is a good practice to share complete pipelines, meaning folder structures, additional files and software specification, as well all custom scripts developed for the analysis. These files can be shared using the same tools as other forms of code, namely GitHub or any other Git hosting services. Alternatively, they can be uploaded to hosting services specialized in workflows, like WorkflowHub [@https://workflowhub.eu/], currently in beta.

When sharing workflows, consider that sharing software versioning is necessary for your collaborators to reproduce your pipeline using their own computing setup. Conda environments, for example, can be easily created from an environment file (in YAML language), which can be exported from an existing environment. Notably, Snakemake and Nexflow can be configured to automatically build isolated environments for each rule or step, enabling running different versions of a program within the same pipeline (which is especially helpful when needing both Python 2 and 3). Besides sharing the specifications of an environment, it is possible to share the environment itself via containers, using platforms like Docker and Singularity, which are especially helpful to share environments with a broader community, as we will discuss in Level 3.

### 2.5 Write manuscripts collaboratively

Writing articles is arguably the main way where we can share our research with the scientific community and for that purpose, the world. However, in a highly interdisciplinary field as computational biology, writing manuscripts is also a collaborative effort, where multiple people is directly involved in the crafting of a manuscripts. The traditional computer tools for writing documents, therefore, are oftentimes not suitable for this type of collaboration, resulting in files with different names jumping from one e-mail inbox to another, resulting in multiple and likely contradictory final versions. Let's avoid this by streamline collaborative manuscript writing with tools made for that purpose.

Big companies have become aware of the need for collaborative writing, developing online applications that can be simultaneously edited by multiple people. Google's GDocs and Microsoft's Office 365 are well-known word processors designed for this purpose, where the text is displayed with the exact appearance than in a printout (know as _What-You-See-Is-What-You-Get_ , or WYSIWYG) and the text can be formatted making use of the internal features of the application. The advantage of these technologies is that they are extremely user-friendly, and require no additional knowledge. They are a good option when one or more of your collaborators seeks simplicity, but they are not specifically tailored for the needs of scientific writing, such as adding references, equations and figures. Fortunately, third-party companies have developed plugins for these applications to add references to your document. Companies like Authorea have developed their own online application specifically designed for writing manuscripts. Authorea, in particular, offers templates for different type of research projects, allows you to manage collaborators from the same platform, and easily add reference from using identifiers (DOI, PubMed, etc.). Consider, nonetheless, that some collaborators may not want to adopt a new tool exclusively for writing manuscripts.

In addition to word editors, text editors are a competitive option to write manuscripts when combined with a markup language—a human-readable computer language that uses tags to delineate formatting elements in a document that will be later rendered. Since the formatting process is internally handled by the application, styling elements (headers, text formatting, equations) can be easily written in text, even achieving greater consistency than word processors. Disciplines closely related to computational biology, such as statistics and mathematics, have historically used the markup language LaTeX for writing articles. This language has a specific syntax to write mathematics constructs as simple text, making it a sound choice for papers with lots of equations. To aid collaborative writing, platforms like Overleaf provide online LaTeX editors, supporting features like real-time editing. In addition to LaTeX, an emerging trend in collaborative writing is to use the lightweight markup language Markdown within the GitHub infrastructure. The software Manubot provides a set of functionalities to write scholarly articles within a GitHub repository, leveraging all the advantages of Git version control and the GitHub hosting platform [@doi:10.1371/journal.pcbi.1007128]. For example, it provides cloud storage, version control, and facilitates the maintainers' work by managing updates via pull requests. The GitHub user interface also allows off-line discussions about the manuscript using issues" and task assignment (See level 3 for tips on project management). Manubot, in particular, accepts citations using manuscripts identifiers and renders automatically renders the article in PDF and HTML formats. As a drawback, it requires technical expertise in Git and familiarity with GitHub; as an upside, its reliable infrastructure scales well to large and open collaborative projects. 
