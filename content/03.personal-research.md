## Level 1: Personal Research

The computational biology "journey" begins with you—more specifically, with the set of skills, tools and practices that you have in place to conduct your research. Taking the time to optimally establish these building blocks will have high payoff later, when you find the need to go back to your research (which will certainly happen). Consider that your most important collaborator is your future self, either of tomorrow or ten years from now. To attend all the fundamental aspects that make up a solid ground to start any computational biology project, we devised a framework involving four main steps (Table 1).

### Step 1: Choose your programming languages

Different programming languages serve distinctive purposes and have different idiosyncrasies. As such, choosing the right programming language for a project depends on your research goals and personal preference or skill. Additionally, communities usually favor the usage and training of some programming languages over others; utilizing such languages may facilitate integrating your work within the existing ecosystem.

As computational biology becomes a data intensive discipline, interacting with high-performance computing (HPC) operating systems has become a hallmark of this field. Commonly, HPC infrastructures use Unix/Linux distributions as their operating system. These platforms are operated from the command line using a command line interpreter known as the "Unix shell". There are multiple versions of Unix shells, being Bash one of the most widely adopted. Besides providing an "user interface", the shell is also a scripting language that allows manipulating files and executing programs through "shell scripts". Unix/Linux operating systems have other interesting perks, such as powerful and fast commands for searching words and manipulating files (e.g. `sed`, `grep` or `join`) as well as the language AWK—a standard feature of Unix/Linux operating systems—that can perform quick text processing, including arithmetic operations.

One of the most common task of any computational biologist is data analysis. The job of a data analyst involves data cleaning, exploration, manipulation, and visualization. Nowadays, Python is the most widely used programming language for data analysis worldwide. Computational biology research had followed this trend, making Python one of the most popular languages for data analysis among researchers. Python acquisition has been facilitated by the availability of packages for biological data analysis easily accessible through package managers such as Pip or Conda. Python has also become one of the standard languages for machine learning and deep learning; increasing usage of these tools in biological research will keep propelling Python as a core programming language in computational biology. In addition to Python, R is the other most prominent language in the field. Arguably, one of R main strengths is the wide array of tools for statistical analysis. Also, as R has been around for several decades, a wide array tools have already been written in this language. Of particular interest is the Bioconductor repository, where many gold-standard tools in computational biology have been published. R usage in data science has deeply benefited from the Tidyverse packages, increasing readability and flow of the traditional R syntax for both data manipulation via `dplyr`, and visualization via `ggplot2`.

Oftentimes, computational biologists require coding their own sets of instructions for processing data via scripts or programs. A script can be described as lightweight program developed to tackle a narrow purpose and usually consisting of a single file. They are most likely written in an interpreted programming language instead of a compiled one. These programming languages are quickly to edit and each instruction can be run interactively, at expense of worse computational performance. In computational biology, the current most common multi-purpose scripting languages are Python and R. When working in a HPC, Shell/Bash scripting is also widely used. Perl and Matlab are also a popular language among bioinformatics and systems biology, respectively. A program, in the other hand, is a larger tool that usually combines multiple scripts and works as a "black box" to the user. It is designed to tackle a larger problem and, thus, is more computationally intensive. To make better use of computational resources, programs are preferably written using compiled languages. Several tools designed for high-weight biological data processing have been written in C/C++. However, in recent years, scientist have been turning to Rust because of its speed, safety and friendly community [@doi:10.1038/d41586-020-03382-2]. Programs can also be written in an interpreted language. especially when computational performance is not a concern. Python and R excel in this area due to their versatility and wide array of modules and libraries available.

Biological data processing is rarely a one-step process. To go from raw data to useful insights several steps need to be taken in a specific order. Moreover, they are often accompanied by a plethora of decisions regarding parameters. Computational biologist have addressed this need by embracing workflow management systems to automate data analysis pipelines. In its most simplified form, a pipeline can be written as a Shell script where a handful of commands are streamlined one after another, using Shell variables and Shell scripting syntax when needed. This approach is suitable for quick single-use applications. However, when the task involves multiples steps, non-linear decision making and internal checks, Shell scripts become cumbersome. For such cases, dedicated bioinformatics workflow systems have been developed. There are multiple bioinformatics workflow managers, but here we will focus on Snakemake and Nextflow. Snakemake is a workflow management system written in Python, which easily allows to incorporate the syntax of the tool with standard Python code. Similarly, Nextflow was build as an extension of the Groovy—a programming language for the Java virtual machine—and can execute any piece of Groovy code. These tools not only streamline data analysis steps, but also have incorporated multiple features over the years, like interacting with job schedulers to be run in HPCs, automated deployment of computational environments (i.e. software and dependencies), and cloud computing support. The Common Workflow Language features another take on data analysis pipelines, delivering a standard for pipeline definition that can be read by different tools.

### Step 2: Setup your working environment

After you have chosen the right language or languages for the task at hand, the next practical question is to decide where to code. The simplest tool available for this purpose are text editors. 

* Notebooks: Data analysis greatly benefits from using notebooks, instead of plain text editors or even IDEs. A notebook is an interactive application that combines code, narrative and visualizations. Common notebooks use either Python or R programming languages and narrative follows markdown syntax, interactive code - no need to compile. While assembly language deals with direct hardware manipulation and performance issues, a machine language is basically binaries read and executed by a computer. An assembler software converts the assembly language into machine code. Low-level programming languages are faster and more memory efficient as compared to their high-level counterparts. 
* IDEs

### Step 3: Define your project structure

* Research templates
* Package managers: A **package manager** or **package**-**management** system is a collection of software tools that automates the process of installing, upgrading, configuring, and removing computer programs for a computer's operating system in a consistent manner.
* Environment managers

### Step 4: Write high-quality code

* Coding good practices, commenting, log de cambios, funciones, decisiones en codigo, standard styling
* Version control

**Table 1**: Steps to start a computational biology project.

| Step                                          | Use case: common tools                                       |
| --------------------------------------------- | ------------------------------------------------------------ |
| **Step 1:** Select your programming languages | &bull; _Interacting with a Unix/Linux HPC_: Shell/Bash<br />&bull; _Data analysis:_ Python, R<br />&bull; _Scrips and tool development:_ Python, R, Perl<br />&bull; _Tool development (high-performance):_ C/C++, Rust<br />&bull; _Research pipelines_: Snakemake (Python), Nextflow (Groovy) |
| **Step 2:** Setup your coding environment     | &bull; _Text editors_: Atom, Sublime, Visual Studio Code, Vim, Emacs<br />&bull; _IDEs_: R Studio, Jupyter Lab, Jet Brains (PyCharm), Spyder<br />&bull; _Notebooks_: Jupyter notebooks, R Markdown, Atom/nteract |
| **Step 3:** Define your project structure     | &bull; _Research templates_: Cookiecutter Data Science, Reproducible Research Project Initialization<br />&bull; _Package managers_: Conda, pip<br />&bull; _Environment managers_: Conda, virtualenv |
| **Step 4:** Write high-quality code           | &bull; _Literate programming_: Markdown, R Markdown, Jupyter Notebooks.<br />&bull; _Coding good practices_: commenting (functions, decisions), styling (variable naming, linter, pep8) <br />&bull; _Version control_: Git and Git GUIs (GitHub Desktop, GitKraken), GitHub/GitLab/BitBucket |

**Table 1 (option 2)**: Steps to start a computational biology project.

<table>
    <thead>
        <tr>
            <th>Step</th>
            <th>Use case</th>
            <th>Common tools<</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=5><b>Step 1:</b> Select your programming languages</td>
            <td rowspan=1>Interacting with a Unix/Linux HPC</td>
            <td>&bull; Shell/Bash</td>
        </tr>
        <tr>
            <td rowspan=1>Data analysis</td>
            <td>&bull; Python<br />&bull; R</td>
        </tr>
        <tr>
            <td rowspan=1>Scrips and tool development:</td>
            <td>&bull; Python<br />&bull; R<br />&bull; Perl</td>
        </tr>
        <tr>
            <td rowspan=1>Tool development (high-performance)</td>
            <td>&bull; C/C++<br />&bull; Rust</td>
        </tr>
        <tr>
            <td rowspan=1>Pipelines</td>
            <td>&bull; Snakemake (Python))<br />&bull; Nextflow (Groovy)</td>
        </tr>
    </tbody>
    <tbody>
        <tr>
            <td rowspan=5><b>Step 2:</b> Setup your coding environment</td>
            <td rowspan=1>Text editors</td>
            <td>&bull; Atom<br />&bull; Sublime<br />&bull; Visual Studio Code<br />&bull; Vim<br />&bull; Emacs</td>
        </tr>
        <tr>
            <td rowspan=1>Notebooks</td>
            <td>&bull; Jupyter Notebooks<br />&bull; R Markdown<br />&bull; Atom (nteract)</td>
        </tr>
        <tr>
            <td rowspan=1>IDEs</td>
            <td>&bull; R Studio<br />&bull; Jupyter Lab<br />&bull; PyCharm<br />&bull; Spyder</td>
        </tr>
    </tbody>
</table>



* Maybe  we can add an appendix with useful ggplot packages: https://github.com/const-ae/ggsignif and patchwork
* Look for a good reference detailing differences between interpreted and compiled languages (low-level vs high-level)